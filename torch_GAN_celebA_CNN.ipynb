{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_GAN_celebA_CNN.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OEkOwwuYTCXlAm3yOivJQWNAYfsc_Z1j",
      "authorship_tag": "ABX9TyM7aMDjodNIPi/OZeiglwEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/torch_GAN/blob/main/torch_GAN_celebA_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbTF80S_B1l1"
      },
      "outputs": [],
      "source": [
        "#Created by Hyunjun JANG\n",
        "#training GAN to check the performance with 3D-celeb image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "import h5py\n",
        "import zipfile\n",
        "import torchvision.datasets\n",
        "import os\n",
        "import imageio\n",
        "import time\n",
        "\n",
        "# location of the HDF5 package, yours may be under /gan/ not /myo_gan/\n",
        "hdf5_file = '/content/drive/MyDrive/Colab Notebooks/Data/img/celeba_aligned_small.h5py'\n",
        "\n",
        "# how many of the 202,599 images to extract and package into HDF5\n",
        "total_images = 20000\n",
        "\n",
        "with h5py.File(hdf5_file, 'w') as hf:\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    with zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/Data/img/source1.zip', 'r') as zf:\n",
        "      for i in zf.namelist():\n",
        "        if (i[-4:] == '.jpg'):\n",
        "          # extract image\n",
        "          ofile = zf.extract(i)\n",
        "          img = imageio.imread(ofile)\n",
        "          os.remove(ofile)\n",
        "\n",
        "          # add image data to HDF5 file with new name\n",
        "          hf.create_dataset('img_align_celeba/'+str(count)+'.jpg', data=img, compression=\"gzip\", compression_opts=9)\n",
        "          \n",
        "          count = count + 1\n",
        "          if (count%1000 == 0):\n",
        "            print(\"images done .. \", count)\n",
        "            pass\n",
        "            \n",
        "          # stop when total_images reached\n",
        "          if (count == total_images):\n",
        "            break\n",
        "          pass\n",
        "\n",
        "        pass\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA가 가능한지 확인\n",
        "# 가능하다면, cuda에 기본 형태를 설정\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "  print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
        "  pass\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "3Cz1MqMsq_w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with h5py.File(hdf5_file, 'r') as file_object:\n",
        "  dataset = file_object['img_align_celeba']\n",
        "  image = numpy.array(dataset['227.jpg'])\n",
        "  print(image.shape)\n",
        "  plt.imshow(image, interpolation='none')\n",
        "  pass"
      ],
      "metadata": {
        "id": "3LOY9mqxgh4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_centre(img, new_width, new_height):\n",
        "    height, width, _ = img.shape\n",
        "    startx = width//2 - new_width//2\n",
        "    starty = height//2 - new_height//2    \n",
        "    return img[  starty:starty + new_height, startx:startx + new_width, :]"
      ],
      "metadata": {
        "id": "xs51oEQ9XazW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebADataset(Dataset):\n",
        "    \n",
        "    def __init__(self, file):\n",
        "        self.file_object = h5py.File(file, 'r')\n",
        "        self.dataset = self.file_object['img_align_celeba']\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if (index >= len(self.dataset)):\n",
        "          raise IndexError()\n",
        "        img = numpy.array(self.dataset[str(index)+'.jpg'])\n",
        "        # 128x128 사각형으로 크롭\n",
        "        img = crop_centre(img, 128, 128)\n",
        "        return torch.cuda.FloatTensor(img).permute(2,0,1).view(1,3,128,128) / 255.0\n",
        "    \n",
        "    def plot_image(self, index):\n",
        "        img = numpy.array(self.dataset[str(index)+'.jpg'])\n",
        "        # 128x128 사각형으로 크롭\n",
        "        img = crop_centre(img, 128, 128)\n",
        "        plt.imshow(img, interpolation='nearest')\n",
        "        pass\n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "1mkarLpDhW3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "celeba_dataset = CelebADataset(hdf5_file)\n",
        "celeba_dataset.plot_image(227)"
      ],
      "metadata": {
        "id": "ulIQ6QWOiEzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random(size) :\n",
        "  random_data = torch.rand(size)\n",
        "  return random_data\n",
        "\n",
        "def generate_random_seed(size):\n",
        "    random_data = torch.randn(size)\n",
        "    return random_data  \n",
        "\n",
        "def generate_random_image(size) : \n",
        "  random_data = torch.rand(size)\n",
        "  return random_data"
      ],
      "metadata": {
        "id": "4xvhGEaooI1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class View(nn.Module):\n",
        "    def __init__(self, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape,\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)"
      ],
      "metadata": {
        "id": "uPUIkajQoJcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Discriminator is learning about generate_real as true pattern and generate_random is false pattern\n",
        "\n",
        "Data_size = 128*128*3\n",
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "        \n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            nn.Conv2d(256, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            nn.Conv2d(256, 3, kernel_size=8, stride=2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "            View(3*10*10),\n",
        "            nn.Linear(3*10*10, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # create loss function\n",
        "        self.loss_function = nn.BCELoss()\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def forward(self, inputs):\n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    \n",
        "    def train(self, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        outputs = self.forward(inputs)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = self.loss_function(outputs, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "        if (self.counter % 3000 == 0):\n",
        "            print(\"counter = \", self.counter)\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def plot_progress(self):\n",
        "        df = pd.DataFrame(self.progress, columns=['Discriminator loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "t1aNINzrVb60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the Discriminator\n",
        "D = Discriminator()\n",
        "D.to(device)\n",
        "targets = torch.cuda.FloatTensor([1.0])\n",
        "non_target = torch.cuda.FloatTensor([0.0])\n",
        "\n",
        "for image_data_tensor in celeba_dataset : \n",
        "  D.train(image_data_tensor, targets)\n",
        "  D.train(generate_random_image((1,3,128,128)), non_target)\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "Z22_RzplVuXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructing Generator\n",
        "\n",
        "class Generator(nn.Module) : \n",
        "  def __init__(self) : \n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "    \n",
        "            nn.Linear(100, 3*11*11),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            \n",
        "         \n",
        "            View((1, 3, 11, 11)),\n",
        "            \n",
        "            nn.ConvTranspose2d(3, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 3, kernel_size=8, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(3), #1,3,128,128\n",
        "        \n",
        "            nn.Sigmoid() \n",
        "    )\n",
        "\n",
        "    self.optimiser = torch.optim.Adam(self.parameters(), lr = 0.0001)\n",
        "    self.counter = 0\n",
        "    self.progress = []\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, inputs) : \n",
        "    return self.model(inputs)\n",
        "\n",
        "  def train(self, D, inputs, targets) : \n",
        "    g_output = self.forward(inputs)\n",
        "    d_output = D.forward(g_output)\n",
        "    loss = D.forward(g_output)\n",
        "    loss = D.loss_function(d_output, targets)\n",
        "\n",
        "    self.counter+=1;\n",
        "    if (self.counter % 10 == 0) :\n",
        "      self.progress.append(loss.item())\n",
        "      pass\n",
        "\n",
        "    self.optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimiser.step()\n",
        "\n",
        "  def plot_progress(self):\n",
        "        df = pd.DataFrame(self.progress, columns=['Generator loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        \n",
        "  pass"
      ],
      "metadata": {
        "id": "FIbjv93gaLGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check a Generator\n",
        "G = Generator()\n",
        "G.to(device)\n",
        "output = G.forward(generate_random_seed(100))\n",
        "img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "\n",
        "plt.imshow(img, interpolation='none', cmap='Reds')"
      ],
      "metadata": {
        "id": "SAD-6yfS5mLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training both Generator and Discriminator for pattern\n",
        "D = Discriminator()\n",
        "D.to(device)\n",
        "G = Generator()\n",
        "G.to(device)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"epoch = \", epoch+1)\n",
        "  for image_data_tensor in celeba_dataset : \n",
        "    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))\n",
        "    D.train(G.forward(generate_random_seed(100)).detach(),torch.cuda.FloatTensor([0.0]))\n",
        "\n",
        "    G.train(D, generate_random_seed(100), torch.cuda.FloatTensor([1.0]))\n",
        "  \n",
        "    pass\n",
        "  pass"
      ],
      "metadata": {
        "id": "4xLvQ9x36hqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the Generator Loss\n",
        "D.plot_progress()\n",
        "G.plot_progress()"
      ],
      "metadata": {
        "id": "cxxn8KEZ7oIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the result of Generator\n",
        "\n",
        "f, axarr = plt.subplots(2,3,figsize = (16,8))\n",
        "for i in range(2) : \n",
        "  for j in range(3) : \n",
        "    output = G.forward(generate_random_seed(100))\n",
        "    img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "    axarr[i,j].imshow(img, interpolation = 'none', cmap = 'Reds')\n",
        "    pass\n",
        "\n",
        "pass"
      ],
      "metadata": {
        "id": "MiG3R4HB8Ogb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check1\n",
        "seed1 = generate_random_seed(100)\n",
        "out1 = G.forward(seed1)\n",
        "img1 = out1.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "plt.imshow(img1, interpolation='none', cmap='Blues')"
      ],
      "metadata": {
        "id": "O-sfkVQpFnO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check2\n",
        "seed2 = generate_random_seed(100)\n",
        "out2 = G.forward(seed2)\n",
        "img2 = out2.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "plt.imshow(img2, interpolation='none', cmap='Blues')"
      ],
      "metadata": {
        "id": "_YKasQg2FslH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check3\n",
        "count = 0\n",
        "\n",
        "# plot a 3 column, 2 row array of generated images\n",
        "f, axarr = plt.subplots(3,4, figsize=(16,8))\n",
        "for i in range(3):\n",
        "    for j in range(4):\n",
        "        seed = seed1 + (seed2 - seed1)/11 * count\n",
        "        output = G.forward(seed)\n",
        "        img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')\n",
        "        count = count + 1\n",
        "        pass\n",
        "    pass"
      ],
      "metadata": {
        "id": "EiAAfkHZFu9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}