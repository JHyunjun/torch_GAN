{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_cGAN_MNIST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rcpOUd7YnIikHfyx1jZzKHzRU_bpy1E2",
      "authorship_tag": "ABX9TyPcC+GV6q2CPuJxZx8Q8QHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/torch_GAN/blob/main/ConditionalGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbTF80S_B1l1"
      },
      "outputs": [],
      "source": [
        "#Created by Hyunjun JANG\n",
        "#training GAN to check the performance with simple pattern\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "csv_file = '/content/sample_data/mnist_test.csv'\n",
        "\n",
        "class MnistDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file):\n",
        "        self.data_df = pd.read_csv(csv_file, header=None)\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        label = self.data_df.iloc[index,0]\n",
        "        target = torch.zeros((10))\n",
        "        target[label] = 1.0\n",
        "        \n",
        "        \n",
        "        image_values = torch.FloatTensor(self.data_df.iloc[index,1:].values) / 255.0\n",
        "        \n",
        "        \n",
        "        return label, image_values, target\n",
        "    \n",
        "    def plot_image(self, index):\n",
        "        img = self.data_df.iloc[index,1:].values.reshape(28,28)\n",
        "        plt.title(\"label = \" + str(self.data_df.iloc[index,0]))\n",
        "        plt.imshow(img, interpolation='none', cmap='Reds')\n",
        "        pass\n",
        "    \n",
        "    pass\n",
        "\n",
        "\n",
        "mnist_dataset = MnistDataset(csv_file)\n",
        "print(np.shape(mnist_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset.plot_image(17)"
      ],
      "metadata": {
        "id": "hKkUXgv7B_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Discriminator is learning about generate_real as true pattern and generate_random is false pattern\n",
        "\n",
        "Data_size = 784+10\n",
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "        \n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(Data_size, 200),\n",
        "            nn.LeakyReLU(0.02),\n",
        "            nn.LayerNorm(200),\n",
        "            nn.Linear(200, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # create loss function\n",
        "        self.loss_function = nn.BCELoss()\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def forward(self, image_tensor, label_tensor):\n",
        "        # simply run model\n",
        "        inputs = torch.cat((image_tensor, label_tensor))\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    \n",
        "    def train(self, inputs, label_tensor, targets):\n",
        "        # calculate the output of the network\n",
        "        outputs = self.forward(inputs, label_tensor)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = self.loss_function(outputs, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "        if (self.counter % 3000 == 0):\n",
        "            print(\"counter = \", self.counter)\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def plot_progress(self):\n",
        "        df = pd.DataFrame(self.progress, columns=['Discriminator loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "t1aNINzrVb60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random(size) :\n",
        "  random_data = torch.rand(size)\n",
        "  return random_data\n",
        "\n",
        "def generate_random_seed(size):\n",
        "    random_data = torch.randn(size)\n",
        "    return random_data  \n",
        "\n",
        "def generate_random_image(size) : \n",
        "  random_data = torch.rand(size)\n",
        "  return random_data\n",
        "\n",
        "def generate_random_one_hot(size) : \n",
        "  label_tensor = torch.zeros((size))\n",
        "  random_idx = random.randint(0, size-1)\n",
        "  label_tensor[random_idx] = 1.0\n",
        "  return label_tensor"
      ],
      "metadata": {
        "id": "H05wVvV153iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the Discriminator\n",
        "D = Discriminator()\n",
        "targets = torch.FloatTensor([1.0])\n",
        "non_target = torch.FloatTensor([0.0])\n",
        "\n",
        "for label, image_data_tensor, label_tensor in mnist_dataset : \n",
        "  D.train(image_data_tensor, label_tensor, targets)\n",
        "  D.train(generate_random_image(784), generate_random_one_hot(10), non_target)\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "Z22_RzplVuXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the performance of Discriminator\n",
        "D.plot_progress()"
      ],
      "metadata": {
        "id": "vA2-i2HFaEsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constructing Generator\n",
        "\n",
        "class Generator(nn.Module) : \n",
        "  def __init__(self) : \n",
        "    super().__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(100+10,200),\n",
        "        nn.LeakyReLU(0.02),\n",
        "        nn.LayerNorm(200),\n",
        "        nn.Linear(200,Data_size-10),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    self.optimiser = torch.optim.Adam(self.parameters(), lr = 0.0001)\n",
        "    self.counter = 0\n",
        "    self.progress = []\n",
        "\n",
        "    pass\n",
        "\n",
        "  def forward(self, seed_tensor, label) : \n",
        "    inputs = torch.cat((seed_tensor, label_tensor))\n",
        "    return self.model(inputs)\n",
        "\n",
        "  def train(self, D, inputs, label_tensor, targets) : \n",
        "    g_output = self.forward(inputs, label_tensor)\n",
        "    d_output = D.forward(g_output, label_tensor)\n",
        "    loss = D.loss_function(d_output, targets)\n",
        "\n",
        "    self.counter+=1;\n",
        "    if (self.counter % 10 == 0) :\n",
        "      self.progress.append(loss.item())\n",
        "      pass\n",
        "\n",
        "    self.optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimiser.step()\n",
        "\n",
        "  def plot_progress(self):\n",
        "        df = pd.DataFrame(self.progress, columns=['Generator loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        \n",
        "  pass\n",
        "  #Checking the result of Generator\n",
        "\n",
        "  def plot_images(self, label) : \n",
        "    label_tensor = torch.zeros((10))\n",
        "    label_tensor[label] = 1.0\n",
        "\n",
        "    f, axarr = plt.subplots(2,3,figsize = (16,8))\n",
        "    for i in range(2) : \n",
        "      for j in range(3) : \n",
        "       axarr[i,j].imshow(G.forward(generate_random_seed(100), label_tensor).detach().cpu().numpy().reshape(28,28), interpolation='none', cmap = 'Reds')\n",
        "      pass\n",
        "    pass\n",
        "  pass"
      ],
      "metadata": {
        "id": "FIbjv93gaLGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check a Generator\n",
        "G = Generator()\n",
        "random_label_0 = generate_random_one_hot(10)\n",
        "output = G.forward(generate_random_seed(100),random_label_0)\n",
        "print(output.shape,output)\n",
        "img = output.detach().numpy().reshape(28,28)\n",
        "plt.imshow(img, interpolation = 'none', cmap = 'Reds')"
      ],
      "metadata": {
        "id": "SAD-6yfS5mLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training both Generator and Discriminator for pattern\n",
        "D = Discriminator()\n",
        "G = Generator()\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"epoch = \", epoch+1)\n",
        "  for label, image_data_tensor, label_tensor in mnist_dataset : \n",
        "    D.train(image_data_tensor, label_tensor,  torch.FloatTensor([1.0]))\n",
        "    random_label = generate_random_one_hot(10)\n",
        "    D.train(G.forward(generate_random_seed(100), random_label).detach(), random_label, torch.FloatTensor([0.0]))\n",
        "    random_label = generate_random_one_hot(10)\n",
        "    G.train(D, generate_random_seed(100), random_label, torch.FloatTensor([1.0]))\n",
        "\n",
        "    pass\n",
        "  pass"
      ],
      "metadata": {
        "id": "4xLvQ9x36hqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the Generator Loss\n",
        "D.plot_progress()\n",
        "G.plot_progress()"
      ],
      "metadata": {
        "id": "cxxn8KEZ7oIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.plot_images(9)"
      ],
      "metadata": {
        "id": "xqVEDg8e2Ab0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check1\n",
        "seed1 = generate_random_seed(100)\n",
        "random_label1 = generate_random_one_hot(10)\n",
        "out1 = G.forward(seed1,random_label1)\n",
        "img1 = out1.detach().numpy().reshape(28,28)\n",
        "plt.imshow(img1, interpolation='none', cmap='Blues')"
      ],
      "metadata": {
        "id": "O-sfkVQpFnO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check2\n",
        "seed2 = generate_random_seed(100)\n",
        "random_label2 = generate_random_one_hot(10)\n",
        "out2 = G.forward(seed2, random_label2)\n",
        "img2 = out2.detach().numpy().reshape(28,28)\n",
        "plt.imshow(img2, interpolation='none', cmap='Blues')"
      ],
      "metadata": {
        "id": "_YKasQg2FslH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check3\n",
        "count = 0\n",
        "\n",
        "# plot a 3 column, 2 row array of generated images\n",
        "f, axarr = plt.subplots(3,4, figsize=(16,8))\n",
        "for i in range(3):\n",
        "    for j in range(4):\n",
        "        seed = seed1 + (seed2 - seed1)/11 * count\n",
        "        random_label3 = generate_random_one_hot(10)\n",
        "        output = G.forward(seed, random_label3)\n",
        "        img = output.detach().numpy().reshape(28,28)\n",
        "        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')\n",
        "        count = count + 1\n",
        "        pass\n",
        "    pass"
      ],
      "metadata": {
        "id": "EiAAfkHZFu9s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}