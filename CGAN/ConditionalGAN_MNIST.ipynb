{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch_cGAN_MNIST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1rcpOUd7YnIikHfyx1jZzKHzRU_bpy1E2",
      "authorship_tag": "ABX9TyNvbdi3pvYzEriLto09FV3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JHyunjun/torch_GAN/blob/main/ConditionalGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbTF80S_B1l1"
      },
      "outputs": [],
      "source": [
        "#Created by Hyunjun JANG\n",
        "#training GAN to check the performance with simple pattern\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "\n",
        "csv_file = '/content/sample_data/mnist_test.csv'\n",
        "\n",
        "class MnistDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, csv_file):\n",
        "        self.data_df = pd.read_csv(csv_file, header=None)\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        label = self.data_df.iloc[index,0]\n",
        "        target = torch.zeros((10))\n",
        "        target[label] = 1.0\n",
        "        \n",
        "        \n",
        "        image_values = torch.FloatTensor(self.data_df.iloc[index,1:].values) / 255.0\n",
        "        \n",
        "        \n",
        "        return label, image_values, target\n",
        "    \n",
        "    def plot_image(self, index):\n",
        "        img = self.data_df.iloc[index,1:].values.reshape(28,28)\n",
        "        plt.title(\"label = \" + str(self.data_df.iloc[index,0]))\n",
        "        plt.imshow(img, interpolation='none', cmap='Reds')\n",
        "        pass\n",
        "    \n",
        "    pass\n",
        "\n",
        "\n",
        "mnist_dataset = MnistDataset(csv_file)\n",
        "print(np.shape(mnist_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_dataset.plot_image(17)"
      ],
      "metadata": {
        "id": "hKkUXgv7B_Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Discriminator is learning about generate_real as true pattern and generate_random is false pattern\n",
        "\n",
        "Data_size = 784+10\n",
        "class Discriminator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "        \n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(784+10, 200),\n",
        "            nn.LeakyReLU(0.02),\n",
        "            nn.LayerNorm(200),\n",
        "            nn.Linear(200, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # create loss function\n",
        "        self.loss_function = nn.BCELoss()\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def forward(self, image_tensor, label_tensor):\n",
        "        # simply run model\n",
        "        inputs = torch.cat((image_tensor, label_tensor))\n",
        "        return self.model(inputs)\n",
        "    \n",
        "    \n",
        "    def train(self, inputs, label_tensor, targets):\n",
        "        # calculate the output of the network\n",
        "        outputs = self.forward(inputs, label_tensor)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = self.loss_function(outputs, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "        if (self.counter % 5000 == 0):\n",
        "            print(\"counter = \", self.counter)\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def plot_progress(self):\n",
        "        df = pd.DataFrame(self.progress, columns=['Discriminator loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "t1aNINzrVb60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random(size) :\n",
        "  random_data = torch.rand(size)\n",
        "  return random_data\n",
        "\n",
        "def generate_random_seed(size):\n",
        "    random_data = torch.randn(size)\n",
        "    return random_data  \n",
        "\n",
        "def generate_random_image(size) : \n",
        "  random_data = torch.rand(size)\n",
        "  return random_data\n",
        "\n",
        "def generate_random_one_hot(size) : \n",
        "  label_tensor = torch.zeros((size))\n",
        "  random_idx = random.randint(0, size-1)\n",
        "  label_tensor[random_idx] = 1.0\n",
        "  return label_tensor"
      ],
      "metadata": {
        "id": "H05wVvV153iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the Discriminator\n",
        "D = Discriminator()\n",
        "targets = torch.FloatTensor([1.0])\n",
        "non_target = torch.FloatTensor([0.0])\n",
        "\n",
        "for label, image_data_tensor, label_tensor in mnist_dataset : \n",
        "  D.train(image_data_tensor, label_tensor, targets)\n",
        "  D.train(generate_random_image(784), generate_random_one_hot(10), non_target)\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "Z22_RzplVuXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the performance of Discriminator\n",
        "D.plot_progress()\n",
        "\n",
        "for i in range(4):\n",
        "  label, image_data_tensor, label_tensor = mnist_dataset[random.randint(0,50)]\n",
        "  print( D.forward( image_data_tensor, label_tensor ).item() )\n",
        "  pass\n",
        "\n",
        "for i in range(4):\n",
        "  print( D.forward( generate_random_image(784), generate_random_one_hot(10) ).item() )\n",
        "  pass"
      ],
      "metadata": {
        "id": "vA2-i2HFaEsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator 클래스\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # 파이토치 부모 클래스 초기화\n",
        "        super().__init__()\n",
        "        \n",
        "        # 신경망 레이어 정의\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(100+10, 200),\n",
        "            nn.LeakyReLU(0.02),\n",
        "\n",
        "            nn.LayerNorm(200),\n",
        "\n",
        "            nn.Linear(200, 784),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # 옵티마이저 생성\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # 진행 측정을 위한 변수 초기화\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "        \n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def forward(self, seed_tensor, label_tensor):        \n",
        "        # 시드와 레이블 연결\n",
        "        inputs = torch.cat((seed_tensor, label_tensor))\n",
        "        return self.model(inputs)\n",
        "\n",
        "\n",
        "    def train(self, D, inputs, label_tensor, targets):\n",
        "        # 신경망 출력 계산\n",
        "        g_output = self.forward(inputs, label_tensor)\n",
        "        \n",
        "        # 판별기에 값 전달\n",
        "        d_output = D.forward(g_output, label_tensor)\n",
        "        \n",
        "        # 오차 계산\n",
        "        loss = D.loss_function(d_output, targets)\n",
        "\n",
        "        # 매 10회마다 에러를 누적하고 카운터를 증가\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "\n",
        "        # 기울기를 초기화 하고 역전파 후 가중치 갱신\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "    \n",
        "    def plot_images(self, label):\n",
        "        label_tensor = torch.zeros((10))\n",
        "        label_tensor[label] = 1.0\n",
        "        # plot a 3 column, 2 row array of sample images\n",
        "        f, axarr = plt.subplots(2,3, figsize=(16,8))\n",
        "        for i in range(2):\n",
        "            for j in range(3):\n",
        "                axarr[i,j].imshow(G.forward(generate_random_seed(100), label_tensor).detach().cpu().numpy().reshape(28,28), interpolation='none', cmap='Blues')\n",
        "                pass\n",
        "            pass\n",
        "        pass\n",
        "    \n",
        "    def plot_progress(self):\n",
        "        df = pd.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "    \n",
        "    pass"
      ],
      "metadata": {
        "id": "FIbjv93gaLGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check a Generator\n",
        "G = Generator()\n",
        "random_label_0 = generate_random_one_hot(10)\n",
        "output = G.forward(generate_random_seed(100),generate_random_one_hot(10))\n",
        "print(output.shape,output)\n",
        "img = output.detach().numpy().reshape(28,28)\n",
        "plt.imshow(img, interpolation = 'none', cmap = 'Reds')"
      ],
      "metadata": {
        "id": "SAD-6yfS5mLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training both Generator and Discriminator for pattern\n",
        "D = Discriminator()\n",
        "G = Generator()\n"
      ],
      "metadata": {
        "id": "4xLvQ9x36hqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 12\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"epoch = \", epoch+1)\n",
        "  for label, image_data_tensor, label_tensor in mnist_dataset : \n",
        "    D.train(image_data_tensor, label_tensor,  torch.FloatTensor([1.0]))\n",
        "    #generate_random = generate_random_seed(100)\n",
        "    random_label = generate_random_one_hot(10)\n",
        "    D.train(G.forward(generate_random_seed(100), random_label).detach(), random_label, torch.FloatTensor([0.0]))\n",
        "    #D.train(G.forward(generate_random, random_label).detach(), random_label, torch.FloatTensor([0.0]))\n",
        "    random_label = generate_random_one_hot(10)\n",
        "    G.train(D, generate_random_seed(100), random_label, torch.FloatTensor([1.0]))\n",
        "    #G.train(D, generate_random, random_label, torch.FloatTensor([1.0]))\n",
        "\n",
        "    pass\n",
        "  pass"
      ],
      "metadata": {
        "id": "oikT1tbWuU3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the Generator Loss\n",
        "D.plot_progress()\n",
        "G.plot_progress()"
      ],
      "metadata": {
        "id": "cxxn8KEZ7oIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.plot_images(9)"
      ],
      "metadata": {
        "id": "xqVEDg8e2Ab0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.plot_images(4)"
      ],
      "metadata": {
        "id": "H3hLG4S5ZZx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.plot_images(1)"
      ],
      "metadata": {
        "id": "4Q9d4IBzsuSU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
